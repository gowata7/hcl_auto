{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "933d00fb-d963-42c0-92c4-e6c55815f1d5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "647799de-2863-4009-91be-f2cc71573afa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ThemeRegistry.enable('ë§‘ì€ê³ ë”•')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from chart_portal import *\n",
    "from table_portal import *\n",
    "from document_portal import *\n",
    "from docx.text.run import *\n",
    "from docx.enum.text import WD_ALIGN_PARAGRAPH\n",
    "\n",
    "# DRM ë°©ì§€(default.docx)\n",
    "def findfile(name, path):\n",
    "    for dirpath, dirname, filename in os.walk(path):\n",
    "        if name in filename:\n",
    "            return os.path.join(dirpath, name)\n",
    "\n",
    "file_path=os.path.abspath(\"\")\n",
    "srcpath = findfile(\"default.docx.org\", file_path)\n",
    "dir, file = os.path.split(srcpath)\n",
    "shutil.copy2(srcpath, dir+\"\\default.docx\")\n",
    "\n",
    "\n",
    "\n",
    "# Document ê¸°ë³¸ í°íŠ¸\n",
    "style = document.styles['Normal']\n",
    "# style.font.name = 'ë§‘ì€ê³ ë”•'\n",
    "style.font.name = 'Calibri'\n",
    "style.font.size = Pt(12)\n",
    "# style._element.rPr.rFonts.set(qn('w:eastAsia'), 'ë§‘ì€ê³ ë”•')\n",
    "style._element.rPr.rFonts.set(qn('w:eastAsia'), 'Calibri')\n",
    "\n",
    "# Chart ê¸°ë³¸ í°íŠ¸\n",
    "alt.themes.register('ë§‘ì€ê³ ë”•', hanfont)\n",
    "alt.themes.enable('ë§‘ì€ê³ ë”•')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0372e2-88a4-4e73-84a1-b54150c52c90",
   "metadata": {},
   "source": [
    "## VM ì§‘ê³„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d869f6d-7438-4d88-8237-df896932a047",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from novaclient import client\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "from novaclient import client\n",
    "from keystoneauth1 import session\n",
    "from keystoneauth1.identity import v3\n",
    "from odf.opendocument import OpenDocumentSpreadsheet\n",
    "from odf.table import Table, TableRow, TableCell\n",
    "from odf.text import P\n",
    "\n",
    "def create_ods_file(file_path, header, data_rows):\n",
    "    print(\" ODS íŒŒì¼ ìƒì„± ì‹œì‘...\")\n",
    "\n",
    "    # Windows ê²½ë¡œ ë§ì¶¤ ì„¤ì •\n",
    "    file_path = file_path.replace(\"/\", \"\\\\\")\n",
    "\n",
    "    #  ë§Œì•½ ë™ì¼í•œ íŒŒì¼ì´ ìˆìœ¼ë©´ ì‚­ì œ\n",
    "    if os.path.exists(file_path):\n",
    "        os.remove(file_path)\n",
    "\n",
    "    #  ODS Document ìƒì„±\n",
    "    doc = OpenDocumentSpreadsheet()\n",
    "    table = Table(name=\"VM_Data\")\n",
    "\n",
    "    #  Header ì¶”ê°€\n",
    "    print(f\"ğŸ“ Header ì¶”ê°€ ì¤‘: {header}\")\n",
    "    header_row = TableRow()\n",
    "    for column_name in header:\n",
    "        cell = TableCell()\n",
    "        # ğŸ‘‰ value-typeì„ stringìœ¼ë¡œ ëª…ì‹œ\n",
    "        cell.setAttribute(\"valuetype\", \"string\")\n",
    "        cell.addElement(P(text=str(column_name)))\n",
    "        header_row.addElement(cell)\n",
    "    table.addElement(header_row)\n",
    "\n",
    "    #  Data ì¶”ê°€\n",
    "    print(f\"ğŸ“ ì´ {len(data_rows)}ê°œì˜ ë°ì´í„°ê°€ ì¶”ê°€ë©ë‹ˆë‹¤.\")\n",
    "    for idx, row in enumerate(data_rows):\n",
    "        # print(f\"â¡ï¸ [{idx+1}/{len(data_rows)}] {row}\")\n",
    "        row_element = TableRow()\n",
    "        for cell_data in row:\n",
    "            if cell_data is None:\n",
    "                cell_data = \"\"\n",
    "            cell = TableCell()\n",
    "            cell.setAttribute(\"valuetype\", \"string\")\n",
    "            cell.addElement(P(text=str(cell_data)))\n",
    "            row_element.addElement(cell)\n",
    "        table.addElement(row_element)\n",
    "\n",
    "    # Tableì„ Spreadsheetì— ì¶”ê°€\n",
    "    print(f\"ğŸ’¾ Spreadsheetì— Table ì¶”ê°€\")\n",
    "    doc.spreadsheet.addElement(table)\n",
    "\n",
    "    #  íŒŒì¼ ì§ì ‘ ì“°ê¸°\n",
    "    print(f\"ğŸ’¾ ODS íŒŒì¼ ì“°ê¸° ì‹œì‘... {file_path}\")\n",
    "    try:\n",
    "        with open(file_path, \"wb\") as f:\n",
    "            doc.write(f)      # ëª…ì‹œì ìœ¼ë¡œ write ìˆ˜í–‰\n",
    "            f.flush()         # ë²„í¼ì— ë‚¨ì•„ìˆëŠ” ë‚´ìš© ë¹„ìš°ê¸°\n",
    "        print(f\"âœ… ODS íŒŒì¼ ìƒì„± ì™„ë£Œ: {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "# íŒŒì¼ëª… ìƒì„± í•¨ìˆ˜\n",
    "def get_file_and_topic_names(current_date):\n",
    "    file_name = f'C:\\\\Beomjun\\\\csv\\\\VM\\\\vm_info_{current_date}.ods'\n",
    "    return file_name\n",
    "\n",
    "def nova_extract(project_name):\n",
    "    current_date = datetime.now().strftime(\"%Y%m%d\")\n",
    "\n",
    "    auth = v3.Password(\n",
    "        auth_url='http://cloud-control-vip.eu-central.openstack.h53:5000/v3',\n",
    "        username='admin',\n",
    "        password='TldhTl1!',\n",
    "        user_domain_name='Default',\n",
    "        project_name='admin',\n",
    "        project_domain_name='Default'\n",
    "    )\n",
    "\n",
    "    sess = session.Session(auth=auth)\n",
    "    nova = client.Client('2.1', session=sess)\n",
    "\n",
    "    # ëª¨ë“  í”„ë¡œì íŠ¸ VM ê°€ì ¸ì˜¤ê¸°\n",
    "    vms = nova.servers.list(search_opts={'all_tenants': 1})\n",
    "\n",
    "    ods_file_path = get_file_and_topic_names(current_date)\n",
    "    print(\"ODS íŒŒì¼ëª…:\", ods_file_path)\n",
    "    \n",
    "    ods_header = [\"id\", \"name\", \"status\", \"flavor\", \"address\", \"availability_zone\", \"hostname\", \"created_at\", \"updated_at\"]\n",
    "    data_rows = []\n",
    "\n",
    "    for vm in vms:\n",
    "        addresses_info = \"\"\n",
    "        for key, values in vm.addresses.items():\n",
    "            for addr_info in values:\n",
    "                addresses_info += f'{key}:{addr_info[\"addr\"]}\\n'\n",
    "        addresses_info = addresses_info.strip()\n",
    "\n",
    "        flavor_id = vm.flavor['id']\n",
    "        flavor = nova.flavors.get(flavor_id)\n",
    "\n",
    "        try:\n",
    "            flavor = nova.flavors.get(flavor_id)\n",
    "            flavor_name = flavor.name\n",
    "        except Exception as e:\n",
    "            flavor_name = \"\"\n",
    "\n",
    "        vm_data = [\n",
    "            vm.id, vm.name, vm.status, flavor_name, addresses_info,\n",
    "            vm._info['OS-EXT-AZ:availability_zone'], vm._info['OS-EXT-SRV-ATTR:host'],\n",
    "            vm.created, vm.updated\n",
    "        ]\n",
    "        data_rows.append(vm_data)\n",
    "        # print(\"data!\", vm_data)\n",
    "\n",
    "    \n",
    "    # print(\"data_rows!\", data_rows)\n",
    "    # ODS íŒŒì¼ ìƒì„±\n",
    "    create_ods_file(ods_file_path, ods_header, data_rows)\n",
    "    return ods_file_path\n",
    "\n",
    "# ì˜¤ë˜ëœ íŒŒì¼ ì •ë¦¬\n",
    "def cleanup(tenants):\n",
    "    time.sleep(1)\n",
    "    current_date = datetime.now().strftime(\"%Y%m%d\")\n",
    "    retention_period = 5\n",
    "    delete_date = (datetime.now() - timedelta(days=retention_period)).strftime(\"%Y%m%d\")\n",
    "    host_dir = 'C://Beomjun//csv//'\n",
    "    file_list = os.listdir(host_dir)\n",
    "\n",
    "    for tenant in tenants:\n",
    "        for file_name in file_list:\n",
    "            if file_name.startswith(f'vm_eu2_{tenant}_') and file_name <= f'vm_eu2_{tenant}_{delete_date}.ods':\n",
    "                file_path = os.path.join(host_dir, file_name)\n",
    "                os.remove(file_path)\n",
    "                print(\"file remove success!\")\n",
    "\n",
    "project_names = ['admin']\n",
    "tenants = ['adminrc']\n",
    "\n",
    "# ê° í”„ë¡œì íŠ¸ì— ëŒ€í•´ í•¨ìˆ˜ ì‹¤í–‰\n",
    "for project_name in project_names:\n",
    "    print(\"This project is\", project_name)\n",
    "    ods_file_path = nova_extract(project_name)\n",
    "\n",
    "# cleanup(tenants)\n",
    "\n",
    "\n",
    "\n",
    "# ë‚ ì§œ ì„¤ì •\n",
    "current_date = datetime.now().strftime(\"%Y%m%d\")\n",
    "yesterday_date = (datetime.now() - timedelta(days=1)).strftime(\"%Y%m%d\")\n",
    "\n",
    "print(\"today:\", current_date)\n",
    "print(\"yesterday:\", yesterday_date)\n",
    "\n",
    "# ê²½ë¡œ ì„¤ì •\n",
    "today_path = f\"C:\\\\Beomjun\\\\csv\\\\VM\\\\vm_info_{current_date}.ods\"\n",
    "yesterday_path = f\"C:\\\\Beomjun\\\\csv\\\\VM\\\\vm_info_{yesterday_date}.ods\"\n",
    "\n",
    "# file_path=os.path.abspath(\"\")\n",
    "# srcpath = findfile(f\"eu_adminrc_{yesterday_date}.csv.org\", file_path)\n",
    "# dir, file = os.path.split(srcpath)\n",
    "# shutil.copy2(srcpath, dir+f\"\\eu_adminrc_{yesterday_date}.csv\")\n",
    "    \n",
    "# CSV ë¡œë“œ\n",
    "df_today = pd.read_excel(today_path, engine='odf')\n",
    "df_yesterday = pd.read_excel(yesterday_path, engine='odf')\n",
    "\n",
    "# ID ê¸°ì¤€ìœ¼ë¡œ ì°¨ì§‘í•© ì—°ì‚°\n",
    "today_ids = set(df_today['id'])\n",
    "yesterday_ids = set(df_yesterday['id'])\n",
    "\n",
    "# ì¶”ê°€ëœ VM: ì˜¤ëŠ˜ì—ëŠ” ìˆê³  ì–´ì œëŠ” ì—†ë˜ ê²ƒ\n",
    "added_ids = today_ids - yesterday_ids\n",
    "df_added = df_today[df_today['id'].isin(added_ids)]\n",
    "\n",
    "# ì‚­ì œëœ VM: ì–´ì œëŠ” ìˆì—ˆëŠ”ë° ì˜¤ëŠ˜ì€ ì—†ëŠ” ê²ƒ\n",
    "deleted_ids = yesterday_ids - today_ids\n",
    "df_deleted = df_yesterday[df_yesterday['id'].isin(deleted_ids)]\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(\"\\nâœ… ì˜¤ëŠ˜ ì¶”ê°€ëœ VM:\")\n",
    "print(df_added)\n",
    "\n",
    "print(\"\\nâŒ ì˜¤ëŠ˜ ì‚­ì œëœ VM:\")\n",
    "print(df_deleted)\n",
    "\n",
    "# for style in document.styles:\n",
    "#     print(style.name)\n",
    "\n",
    "document.add_heading('VM í˜„í™©', level=1) \n",
    "total = len(df_today)\n",
    "\n",
    "document.add_paragraph(f'ì´ {total}ê±´', style='List Bullet')\n",
    "\n",
    "# Pivoting\n",
    "df = preprocess_df(df_today)\n",
    "# pivot, total = getPivotTable(df, month)\n",
    "\n",
    "# Chart - Pie ì°¨íŠ¸\n",
    "region_pivot, _ = getPivotTable_new(df, 'Region')\n",
    "tenant_pivot, _ = getPivotTable_new(df, 'Tenant')\n",
    "\n",
    "source1 = region_pivot\n",
    "source2 = tenant_pivot\n",
    "\n",
    "print(source1)\n",
    "print(source2)\n",
    "\n",
    "# Chart\n",
    "# if incompleted == 0:\n",
    "chart1 = getPieChart_region(source1)\n",
    "chart2 = getPieChart_tenant(source2)\n",
    "# else:\n",
    "#     source = flatten_2d(data)\n",
    "#     chart = getStackedHBarChart(source)    \n",
    "\n",
    "# source = pivot\n",
    "# if incompleted == 0:\n",
    "#     chart = getPieChart(source)\n",
    "# else:\n",
    "#     chart = getStackedHBarChart1(source)\n",
    "chart1.save(f'./charts/vm_1.png')\n",
    "chart2.save(f'./charts/vm_2.png')\n",
    "\n",
    "table = document.add_table(rows=1, cols=2)\n",
    "\n",
    "# ----------- ì¢Œì¸¡ ì…€ (ë¦¬ì „ë³„) ------------\n",
    "cell = table.rows[0].cells[0]\n",
    "paragraph = cell.paragraphs[0]\n",
    "paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER  # ìˆ˜í‰ ì¤‘ì•™ ì •ë ¬\n",
    "run = paragraph.add_run(\"ë¦¬ì „ë³„\")\n",
    "run.font.size = Pt(12)  # í°íŠ¸ í¬ê¸° ì¡°ì ˆ (ì„ íƒ)\n",
    "run.bold = True  # êµµê²Œ (ì„ íƒ)\n",
    "\n",
    "# ì´ë¯¸ì§€ ì¶”ê°€ (ë³„ë„ ë¬¸ë‹¨ ìƒì„±í•˜ì—¬ ì•„ë˜ë¡œ ì •ë ¬ë˜ê²Œ)\n",
    "paragraph_img = cell.add_paragraph()\n",
    "paragraph_img.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "run_img = paragraph_img.add_run()\n",
    "run_img.add_picture('./charts/vm_1.png', width=Inches(3.3))\n",
    "\n",
    "# ----------- ìš°ì¸¡ ì…€ (í…Œë„ŒíŠ¸ë³„) ------------\n",
    "cell = table.rows[0].cells[1]\n",
    "paragraph = cell.paragraphs[0]\n",
    "paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "run = paragraph.add_run(\"í…Œë„ŒíŠ¸ë³„\")\n",
    "run.font.size = Pt(12)\n",
    "run.bold = True\n",
    "\n",
    "paragraph_img = cell.add_paragraph()\n",
    "paragraph_img.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "run_img = paragraph_img.add_run()\n",
    "run_img.add_picture('./charts/vm_2.png', width=Inches(3.3))\n",
    "\n",
    "# table = document.add_table(rows=1, cols=2)\n",
    "# # --- get the first cell of the first row ---\n",
    "# cell = table.rows[0].cells[0]\n",
    "# # --- by default a cell has one paragraph with zero runs ---\n",
    "# paragraph = cell.paragraphs[0]\n",
    "# # --- add a run in which to place the picture ---\n",
    "# run = paragraph.add_run()\n",
    "# # --- add the picture to that run ---\n",
    "# run.add_text(\"{0:^42}ë¦¬ì „ë³„\".format(''))\n",
    "# run.add_picture(f'./charts/vm_1.png', width=Inches(3.3))\n",
    "# cell = table.rows[0].cells[1]\n",
    "# # --- by default a cell has one paragraph with zero runs ---\n",
    "# paragraph = cell.paragraphs[0]\n",
    "# # --- add a run in which to place the picture ---\n",
    "# run = paragraph.add_run()\n",
    "# # --- add the picture to that run ---\n",
    "# run.add_text(\"{0:^42}í…Œë„ŒíŠ¸ë³„\".format(''))\n",
    "# run.add_picture(f'./charts/vm_2.png', width=Inches(3.3))\n",
    "\n",
    "# document.add_paragraph(f'ì›”ë³„ ì¶”ì„¸', style='List Bullet')\n",
    "# document.add_picture(f'./charts/cpm_{regions}_{y}_{m}_{d}_2.png')\n",
    "\n",
    "# Document\n",
    "document.add_paragraph(f'ì „ì¼ ëŒ€ë¹„ ì¶”ê°€ëœ VM({len(df_added)}ê±´)', style='List Bullet')\n",
    "# A-B (ì‚­ì œëœ ê±´)\n",
    "# df_result_sub = pd.concat([df_premonth,df_curmonth,df_curmonth]).drop_duplicates(keep=False)\n",
    "# print(df_result_sub)\n",
    "\n",
    "if len(df_added) == 0:\n",
    "    pass\n",
    "else:\n",
    "    addTable3(df_added)\n",
    "    \n",
    "p = document.add_paragraph('')\n",
    "run = p.add_run()\n",
    "run.add_break(WD_BREAK.LINE)\n",
    "\n",
    "document.add_paragraph(f'ì „ì¼ ëŒ€ë¹„ ì‚­ì œëœ VM({len(df_deleted)}ê±´)', style='List Bullet')\n",
    "# A-B (ì‚­ì œëœ ê±´)\n",
    "# df_result_sub = pd.concat([df_premonth,df_curmonth,df_curmonth]).drop_duplicates(keep=False)\n",
    "# print(df_result_sub)\n",
    "\n",
    "if len(df_deleted) == 0:\n",
    "    pass\n",
    "else:\n",
    "    addTable3(df_deleted)\n",
    "\n",
    "document.add_page_break()\n",
    "\n",
    "document.save(f'C:\\\\Beomjun\\\\csv\\\\vm_report_{current_date}.docx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093de1c4-c694-4845-b940-5ff357a33ff3",
   "metadata": {},
   "source": [
    "## ìŠ¤í† ë¦¬ì§€ ìš©ëŸ‰ ìˆ˜ì§‘(Cinder+Manila)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4619c3-6e8f-4f25-9af7-005957b2bd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from novaclient import client\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "from keystoneauth1 import session\n",
    "from keystoneauth1.identity import v3\n",
    "from odf.opendocument import OpenDocumentSpreadsheet\n",
    "from odf.table import Table, TableRow, TableCell\n",
    "from odf.text import P\n",
    "from cinderclient import client as cinder_client\n",
    "from manilaclient import client as manila_client\n",
    "\n",
    "def create_ods_file(file_path, sheet_data_list):\n",
    "    print(\"ODS íŒŒì¼ ìƒì„± ì‹œì‘...\")\n",
    "\n",
    "    if os.path.exists(file_path):\n",
    "        os.remove(file_path)\n",
    "\n",
    "    doc = OpenDocumentSpreadsheet()\n",
    "\n",
    "    for sheet_name, header, data_rows in sheet_data_list:\n",
    "        print(f\"ğŸ“„ ì‹œíŠ¸ ìƒì„±: {sheet_name}\")\n",
    "        table = Table(name=sheet_name)\n",
    "\n",
    "        # Header\n",
    "        header_row = TableRow()\n",
    "        for col in header:\n",
    "            cell = TableCell(valuetype=\"string\")\n",
    "            cell.addElement(P(text=str(col)))\n",
    "            header_row.addElement(cell)\n",
    "        table.addElement(header_row)\n",
    "\n",
    "        # Data rows\n",
    "        for row in data_rows:\n",
    "            row_element = TableRow()\n",
    "            for item in row:\n",
    "                cell = TableCell(valuetype=\"string\")\n",
    "                cell.addElement(P(text=str(item if item is not None else \"\")))\n",
    "                row_element.addElement(cell)\n",
    "            table.addElement(row_element)\n",
    "\n",
    "        doc.spreadsheet.addElement(table)\n",
    "\n",
    "    # Save file\n",
    "    with open(file_path, \"wb\") as f:\n",
    "        doc.write(f)\n",
    "        f.flush()\n",
    "\n",
    "    print(f\"âœ… ODS ì €ì¥ ì™„ë£Œ: {file_path}\")\n",
    "\n",
    "# íŒŒì¼ëª… ìƒì„± í•¨ìˆ˜\n",
    "def get_file_and_topic_names(current_date):\n",
    "    file_name = f'C:\\\\Beomjun\\\\csv\\\\Volume\\\\volume_info_{current_date}.ods'\n",
    "    return file_name\n",
    "\n",
    "def extract_cinder_data(session):\n",
    "    cinder = cinder_client.Client('3', session=session)\n",
    "    volumes = cinder.volumes.list(search_opts={'all_tenants': 1})\n",
    "\n",
    "    header = [\"tenant\", \"id\", \"name\", \"size\", \"status\", \"volume_type\", \"created_at\", \"availability_zone\"]\n",
    "    data = []\n",
    "\n",
    "    for v in volumes:\n",
    "        volume_type = v.volume_type or \"\"\n",
    "        tenant = \"PRD\" if \"prd\" in volume_type.lower() else \"STG\" if \"stg\" in volume_type.lower() else \"\"\n",
    "\n",
    "        row = [\n",
    "            tenant,\n",
    "            v.id,\n",
    "            v.name,\n",
    "            v.size,\n",
    "            v.status,\n",
    "            volume_type,\n",
    "            v.created_at,\n",
    "            v.availability_zone,\n",
    "        ]\n",
    "        data.append(row)\n",
    "\n",
    "    return (\"Cinder_Volumes\", header, data)\n",
    "\n",
    "def extract_manila_data(session):\n",
    "    manila = manila_client.Client('2', session=session)\n",
    "    shares = manila.shares.list(search_opts={'all_tenants': 1})\n",
    "\n",
    "    header = [\"tenant\", \"id\", \"name\", \"size\", \"status\", \"volume_type\", \"created_at\", \"share_proto\", \"export_location\"]\n",
    "    data = []\n",
    "\n",
    "    for s in shares:\n",
    "        volume_type = s.volume_type or \"\"\n",
    "        tenant = \"PRD\" if \"prd\" in volume_type.lower() else \"STG\" if \"stg\" in volume_type.lower() else \"\"\n",
    "\n",
    "        row = [\n",
    "            tenant,\n",
    "            s.id,\n",
    "            s.name,\n",
    "            s.size,\n",
    "            s.status,\n",
    "            s.volume_type,\n",
    "            s.created_at,\n",
    "            s.share_proto,\n",
    "            s.export_location\n",
    "        ]\n",
    "        data.append(row)\n",
    "\n",
    "    return (\"Manila_Shares\", header, data)\n",
    "\n",
    "\n",
    "def nova_extract():\n",
    "    current_date = datetime.now().strftime(\"%Y%m%d\")\n",
    "\n",
    "    auth = v3.Password(\n",
    "        auth_url='http://cloud-control-vip.eu-central.openstack.h53:5000/v3',\n",
    "        username='admin',\n",
    "        password='TldhTl1!',\n",
    "        user_domain_name='Default',\n",
    "        project_name='admin',\n",
    "        project_domain_name='Default'\n",
    "    )\n",
    "\n",
    "    sess = session.Session(auth=auth)\n",
    "    nova = client.Client('2.1', session=sess)\n",
    "\n",
    "    ods_file_path = get_file_and_topic_names(current_date)\n",
    "    print(\"ODS íŒŒì¼ëª…:\", ods_file_path)\n",
    "\n",
    "    # Cinder & Manila\n",
    "    cinder_sheet = extract_cinder_data(sess)\n",
    "    manila_sheet = extract_manila_data(sess)\n",
    "\n",
    "    # #----------------------------------------------------\n",
    "    # # í‚¤ê°’ í™•ì¸ \n",
    "    # cinder = cinder_client.Client('3', session=sess)\n",
    "    # volumes = cinder.volumes.list(search_opts={'all_tenants': 1})\n",
    "    # # ì˜ˆ: ì²« ë²ˆì§¸ ë³¼ë¥¨ì˜ ëª¨ë“  í‚¤ í™•ì¸\n",
    "    # if volumes:\n",
    "    #     v = volumes[0]  # ë¦¬ìŠ¤íŠ¸ì—ì„œ ì²« ë²ˆì§¸ ë³¼ë¥¨ ì„ íƒ\n",
    "    #     volume_dict = v.to_dict()\n",
    "    \n",
    "    #     print(\"ğŸ” Cinder Volume ëª¨ë“  í•„ë“œ:\")\n",
    "    #     for key in volume_dict:\n",
    "    #         print(f\"{key}: {volume_dict[key]}\")\n",
    "    # else:\n",
    "    #     print(\"â— ë³¼ë¥¨ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    # manila = manila_client.Client('2', session=sess)\n",
    "    # shares = manila.shares.list(search_opts={'all_tenants': 1})\n",
    "    # if shares:\n",
    "    #     v = shares[0]  # ë¦¬ìŠ¤íŠ¸ì—ì„œ ì²« ë²ˆì§¸ ë³¼ë¥¨ ì„ íƒ\n",
    "    #     share_dict = v.to_dict()\n",
    "    \n",
    "    #     print(\"ğŸ” share Volume ëª¨ë“  í•„ë“œ:\")\n",
    "    #     for key in share_dict:\n",
    "    #         print(f\"{key}: {share_dict[key]}\")\n",
    "    # else:\n",
    "    #     print(\"â— ë³¼ë¥¨ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    # #-----------------------------------------------------\n",
    "    \n",
    "    # ì‹œíŠ¸ ë°ì´í„° ë¦¬ìŠ¤íŠ¸ êµ¬ì„±\n",
    "    sheets = [cinder_sheet, manila_sheet]\n",
    "    create_ods_file(ods_file_path, sheets)\n",
    "\n",
    "nova_extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ab4c2a-233f-42be-bc89-2417280f6ae7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33b7bdcd-6b43-4a59-bd57-dc10da7f4813",
   "metadata": {},
   "source": [
    "## ìŠ¤í† ë¦¬ì§€ ìš©ëŸ‰ ìˆ˜ì§‘(ìº¡ì²˜)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b064e3cc-0164-4194-8af9-e67a02a639de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from selenium import webdriver\n",
    "from threading import Event\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "import subprocess\n",
    "import platform\n",
    "import certifi\n",
    "import threading\n",
    "import sys\n",
    "import urllib3\n",
    "import zipfile\n",
    "\n",
    "screenshots_path = 'ScreenShots'\n",
    "isExist = os.path.exists(screenshots_path)\n",
    "\n",
    "if not isExist:\n",
    "    os.makedirs(screenshots_path)\n",
    "    print(\"The new directory is created!\")\n",
    "\n",
    "# Chrome ë²„ì „ ë³€ê²½ ì‹œ, Chrome webdriver ì„¤ì¹˜\n",
    "# https://googlechromelabs.github.io/chrome-for-testing/#stable\n",
    "\n",
    "import winreg\n",
    "import requests\n",
    "\n",
    "def get_chrome_version_from_registry():\n",
    "    reg_paths = [\n",
    "        r\"SOFTWARE\\Google\\Chrome\\BLBeacon\",  # ì¼ë°˜ ì„¤ì¹˜\n",
    "        r\"SOFTWARE\\WOW6432Node\\Google\\Chrome\\BLBeacon\"  # 32bit ì„¤ì¹˜ ê²½ë¡œ\n",
    "    ]\n",
    "\n",
    "    for reg_path in reg_paths:\n",
    "        try:\n",
    "            reg_key = winreg.OpenKey(winreg.HKEY_CURRENT_USER, reg_path)\n",
    "            version, _ = winreg.QueryValueEx(reg_key, \"version\")\n",
    "            winreg.CloseKey(reg_key)\n",
    "            return version\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "\n",
    "    print(\"[ERROR] Chrome version not found in registry.\")\n",
    "    return None\n",
    "\n",
    "# ğŸ“Œ 2. ë‹¤ìš´ë¡œë“œ ë° ì„¤ì¹˜\n",
    "def download_and_install_chromedriver(chrome_version):\n",
    "    major_version = chrome_version.split('.')[0]\n",
    "    # base_url = f\"https://edgedl.me.gvt1.com/edgedl/chrome/chrome-for-testing/{chrome_version}/win64/chromedriver-win64.zip\"\n",
    "    base_url = f\"https://storage.googleapis.com/chrome-for-testing-public/{chrome_version}/win64/chromedriver-win64.zip\"\n",
    "\n",
    "    print(f\"[INFO] Downloading ChromeDriver for version {chrome_version}...\")\n",
    "    r = requests.get(base_url, stream=True)\n",
    "    if r.status_code != 200:\n",
    "        print(f\"[ERROR] Failed to download chromedriver from {base_url}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    zip_path = 'chromedriver.zip'\n",
    "    with open(zip_path, 'wb') as f:\n",
    "        f.write(r.content)\n",
    "\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall()\n",
    "\n",
    "    # chromedriver ìœ„ì¹˜ë¡œ ì´ë™\n",
    "    shutil.move(\"chromedriver-win64/chromedriver.exe\", \"./chromedriver.exe\")\n",
    "    shutil.rmtree(\"chromedriver-win64\")\n",
    "    os.remove(zip_path)\n",
    "    print(\"[INFO] ChromeDriver installed successfully.\")\n",
    "\n",
    "chrome_version = get_chrome_version_from_registry()\n",
    "print(f\"[INFO] Detected Chrome version: {chrome_version}\")\n",
    "download_and_install_chromedriver(chrome_version)\n",
    "\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "exit_event = Event()\n",
    "os.environ['WDM_SSL_VERIFY'] = '0'\n",
    "driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))\n",
    "driver.implicitly_wait(60)\n",
    "\n",
    "# ì›¹ë“œë¼ì´ë²„ í´ë˜ìŠ¤ (ìƒì„±ì/ì†Œë©¸ì)\n",
    "class Driver:\n",
    "    def __init__(self):\n",
    "        options = webdriver.ChromeOptions()\n",
    "        options.add_argument(\"--headless=new\")  # ìµœì‹  headless ëª¨ë“œ\n",
    "        options.add_argument(\"--disable-gpu\")  # í•„ìš” ì‹œ ì œê±°\n",
    "        options.add_argument(\"--enable-unsafe-swiftshader\")\n",
    "        options.add_argument(\"--use-gl=swiftshader\")\n",
    "        # options.add_argument(\"--window-size=1920,1080\")\n",
    "        options.add_argument(\"--no-sandbox\")\n",
    "        options.add_argument(\"--disable-infobars\")\n",
    "        options.add_argument(\"--allow-running-insecure-content\")\n",
    "        options.add_argument(\"--ignore-certificate-errors\")\n",
    "        options.add_argument(\"--disable-extensions\")\n",
    "\n",
    "        try:\n",
    "            # ğŸ”¥ í•µì‹¬: ChromeDriverManagerë¡œ ì„¤ì¹˜í•˜ê³  serviceë¡œ ë„˜ê¹€\n",
    "            # service = Service(ChromeDriverManager().install())\n",
    "            service = Service(executable_path=\"C:/Beomjun/chromedriver.exe\")\n",
    "            self.driver = webdriver.Chrome(service=service, options=options)\n",
    "        except Exception as e:\n",
    "            print(\"âŒ WebDriver ìƒì„± ì‹¤íŒ¨:\", e)\n",
    "            raise\n",
    "        # service = Service(executable_path='chromedriver')  # ë˜ëŠ” ì „ì²´ ê²½ë¡œ\n",
    "        # self.driver = webdriver.Chrome(service=service, options=options)\n",
    "        # self.driver = webdriver.Chrome(executable_path='chromedriver', options=options)\n",
    "        self.driver.set_window_size(1920,1080) \n",
    "        sleep(10)\n",
    "        self.driver.maximize_window()\n",
    "\n",
    "    def __del__(self):\n",
    "        try:   \n",
    "            self.driver.quit() # clean up driver when we are cleaned up\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "thread_local = threading.local()\n",
    "\n",
    "# ì›¹í˜ì´ì§€ ë¡œê·¸ì¸ ì œê³µ\n",
    "def login(driver, url, userid, userid_xpath, passwd, passwd_xpath, login_xpath):\n",
    "    try:\n",
    "        # Grafana ë¡œê·¸ì¸ í˜ì´ì§€ë¡œ ì´ë™\n",
    "        driver.get(url)\n",
    "        driver.switch_to.default_content()\n",
    "        driver.switch_to.parent_frame()\n",
    "\n",
    "        try:\n",
    "            # ê³ ê¸‰ ë²„íŠ¼ í´ë¦­\n",
    "            driver.find_element('xpath', '//*[@id=\"details-button\"]').click()\n",
    "\n",
    "            # ì´ë™ ë²„íŠ¼ í´ë¦­\n",
    "            driver.find_element('xpath', '//*[@id=\"proceed-link\"]').click()\n",
    "\n",
    "            # Hcloud ì¶”ê°€\n",
    "            driver.find_element('xpath', '//*[@id=\"reactRoot\"]/div/main/div[3]/div/div[2]/div/div[2]/div[2]/a').click() \n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "     \n",
    "        username = driver.find_element('xpath', userid_xpath)    \n",
    "        print(\"idì…ë ¥ ì„±ê³µ\"+url)    \n",
    "        username.clear()\n",
    "        username.send_keys(userid)\n",
    "        sleep(3)\n",
    "        \n",
    "        password = driver.find_element('xpath', passwd_xpath)\n",
    "        print(\"pwì…ë ¥ ì„±ê³µ\"+url) \n",
    "        password.clear()\n",
    "        password.send_keys(passwd)\n",
    "        sleep(3)\n",
    "\n",
    "        # Login ë²„íŠ¼ í´ë¦­\n",
    "        driver.find_element('xpath', login_xpath).click()\n",
    "        print(\"loginì‹œë„ì¤‘---->>\"+url)\n",
    "        sleep(3)\n",
    "   \n",
    "    except Exception as e:\n",
    "        return None\n",
    "        \n",
    "    return driver\n",
    "\n",
    "\n",
    "# ë¡œê·¸ì¸ ì •ë³´ ë”•ì…”ë„ˆë¦¬\n",
    "login_info = {\n",
    "    \"01_EU_Hcloud_Storage\": {\n",
    "        \"url\": \"https://hubble-euce.platform.hcloud.io/grafana/login/generic_oauth\",\n",
    "        # \"url\": \"https://sso.hcloud.hmc.co.kr/auth/realms/hcloud/protocol/openid-connect/auth?client_id=iam-client&redirect_uri=http%3A%2F%2Fhubble-euce.platform.hcloud.io%2Fgrafana%2Flogin%2Fgeneric_oauth&response_type=code&scope=openid+email+profile&state=6kBGz08USQFE2sxJSKZl9LSlao6N9aQCqaBfpIM03cs%3D\",\n",
    "        \"userid\": \"cocop\",\n",
    "        \"passwd\": \"cocop\",\n",
    "        \"userid_xpath\": '//*[@id=\"username\"]',\n",
    "        \"passwd_xpath\": '//*[@id=\"password\"]',\n",
    "        \"login_xpath\": '//*[@id=\"kc-form-login\"]/button'\n",
    "    },\n",
    "}\n",
    "\n",
    "def create_driver(bot):\n",
    "    the_driver = getattr(thread_local, 'the_driver', None)\n",
    "    print(the_driver)\n",
    "    # if the_driver is None:\n",
    "    try:\n",
    "        the_driver = Driver()\n",
    "        setattr(thread_local, 'the_driver', the_driver)\n",
    "        print(\"ìƒˆë“œë¼ì´ë²„ ìƒì„±ì¤‘~\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "    driver = the_driver.driver\n",
    "\n",
    "    print(\"-----create_driver=\"+bot+\"------\")\n",
    "    sleep(3)\n",
    "\n",
    "    try:\n",
    "        login_data = login_info.get(bot)\n",
    "        if login_data:\n",
    "            url = login_data[\"url\"]\n",
    "            userid = login_data[\"userid\"]\n",
    "            passwd = login_data[\"passwd\"]\n",
    "            userid_xpath = login_data[\"userid_xpath\"]\n",
    "            passwd_xpath = login_data[\"passwd_xpath\"]\n",
    "            login_xpath = login_data[\"login_xpath\"]\n",
    "            driver=login(driver, url, userid, userid_xpath, passwd, passwd_xpath, login_xpath)\n",
    "            if driver is None: \n",
    "                return None\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    return driver\n",
    "\n",
    "\n",
    "def capture_screen(bot):\n",
    "    \n",
    "    try:\n",
    "        driver = create_driver(bot)\n",
    "        \n",
    "        if driver is None:\n",
    "            print(\"ë“œë¼ì´ë²„ ìƒì„± ì‹¤íŒ¨\")\n",
    "            return  # ë“œë¼ì´ë²„ ìƒì„± ì‹¤íŒ¨ ì‹œ í•¨ìˆ˜ ì¢…ë£Œ\n",
    "        print(\"----\"+bot+\"ìº¡ì²˜í•¨ìˆ˜ì‹œì‘---\")\n",
    "        print(f\"Capturing the screens started at {datetime.now()}\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        # ìµœì¢…(ëŒ€ì‹œë³´ë“œ) í˜ì´ì§€ ë° ì €ì¥íŒŒì¼ ì´ë¦„ ì„¤ì •\n",
    "        urls = {\n",
    "            \"01_EU_Hcloud_Storage\": \"https://hubble-euce.platform.hcloud.io/grafana/d/dongheon-euce/netapp-euce-summary?orgId=41&viewPanel=2&from=now-3h&to=now\",\n",
    "        }\n",
    "        filename = f'{screenshots_path}/{bot}_{datetime.now().strftime(\"%Y%m%d_%H%M\")}.png'\n",
    "        url = urls.get(bot)\n",
    "        print(\"url:\",url)\n",
    "        print(\"bot:\",bot)\n",
    "\n",
    "        if url: \n",
    "            if bot == '01_EU_Hcloud_Storage':\n",
    "                driver.get(url)\n",
    "                # driver.implicitly_wait(30)\n",
    "                sleep(30)\n",
    "                \n",
    "                WebDriverWait(driver, 20).until(\n",
    "                    EC.element_to_be_clickable((By.XPATH, '//*[@id=\"mega-menu-toggle\"]'))\n",
    "                ).click()\n",
    "                driver.execute_script(\"document.querySelector('#mega-menu-toggle').click();\")\n",
    "                sleep(5)\n",
    "                driver.set_window_size(1920, 1300)\n",
    "                # driver.maximize_window()\n",
    "\n",
    "                # sleep(30)\n",
    "                # driver.execute_script(\"document.body.style.zoom=0.75\")\n",
    "                # element = driver.find_element('xpath', '//*[@id=\"mega-menu-toggle\"]')\n",
    "                # if element.is_displayed():\n",
    "                #     element.click()\n",
    "                #     print(\"click success!\")\n",
    "                # else:\n",
    "                #     print(\"Element is not visible in headless mode\")\n",
    "\n",
    "\n",
    "                # driver.set_window_size(1920, 1500)\n",
    "                # driver.maximize_window()\n",
    "                # sleep(10)\n",
    "                # get total page dimensions\n",
    "                # total_width = driver.execute_script(\"return document.body.scrollWidth\")\n",
    "                # total_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "                # set to full size\n",
    "                # driver.set_window_size(total_width, total_height)\n",
    "                # sleep(2)\n",
    "\n",
    "                # zoom out\n",
    "                sleep(5)\n",
    "                # driver.execute_script(\"document.body.style.zoom='0.50'\")\n",
    "                # sleep(2)\n",
    "                # driver.execute_script(\"document.body.style.zoom='0.75'\")\n",
    "                # sleep(10)\n",
    "                driver.save_screenshot(filename)    \n",
    "                driver.close()\n",
    "                driver.quit()\n",
    "                print('ìŠ¤í† ë¦¬ì§€ ìº¡ì³ ì™„ë£Œ!')\n",
    "\n",
    "            else:\n",
    "                \n",
    "                driver.get(url)\n",
    "                sleep(30)\n",
    "                driver.set_window_size(1920, 1080)\n",
    "                driver.maximize_window()\n",
    "               \n",
    "                sleep(50)\n",
    "                driver.execute_script(\"document.body.style.zoom=0.75\")\n",
    "                sleep(30)\n",
    "                driver.save_screenshot(filename)\n",
    "                driver.close()\n",
    "                driver.quit()\n",
    "        else: \n",
    "            print(\"Error occurred while capture!!\")\n",
    "        print(\"----\"+bot+\"ìº¡ì²˜í•¨ìˆ˜ì¢…ë£Œ-----\")\n",
    "    # ì˜ˆì™¸ ì²˜ë¦¬\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "        print(\"\\n... Program Stopped Manually!\")\n",
    "        return\n",
    "\n",
    "def main_capture():\n",
    "\n",
    "    number_threads = 1\n",
    "    \n",
    "    bots = [\n",
    "        '01_EU_Hcloud_Storage',\n",
    "    ]\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=number_threads) as pool:\n",
    "        try:\n",
    "            pool.map(capture_screen, bots)\n",
    "        except KeyboardInterrupt:\n",
    "            print('Caught keyboardinterrupt')\n",
    "            pass\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        main_capture()\n",
    "    except KeyboardInterrupt:\n",
    "        print('Caught keyboardinterrupt')\n",
    "        pass\n",
    "\n",
    "    import gc\n",
    "    gc.collect() # a little extra insurance\n",
    "    print(\"---------------------------end----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162800ff-2bf0-42f8-8b29-10774c74dabd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43f71c7e-e49f-49cc-88f8-f3bec2c06744",
   "metadata": {},
   "source": [
    "## Proxmox ìˆ˜ì§‘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff86689-e5f8-46e9-b5ba-eebcd52bda6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from proxmoxer import ProxmoxAPI\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "# ì—¬ëŸ¬ Proxmox ì„œë²„ ì—°ê²° ì •ë³´ ë¦¬ìŠ¤íŠ¸\n",
    "proxmox_servers = [\n",
    "    {'host': 'proxmox-eu-central-1.hcloud.io:8006', 'user': 'root@pam', 'password': 'EUccs2!@#$'},\n",
    "    {'host': 'proxmox-lms-prd-eu-central-1.hcloud.io:8006', 'user': 'root@pam', 'password': 'EUccs2!@#$'},\n",
    "    {'host': 'proxmox-lms-stg-eu-central-1.hcloud.io:8006', 'user': 'root@pam', 'password': 'EUccs2!@#$'},\n",
    "    {'host': 'proxmox-eu-central-2.hcloud.io:8006', 'user': 'root@pam', 'password': 'EUccs2!@#$'},\n",
    "    {'host': 'proxmox-lms-prd-eu-central-2.hcloud.io:8006', 'user': 'root@pam', 'password': 'EUccs2!@#$'},\n",
    "    {'host': 'proxmox-lms-stg-eu-central-2.hcloud.io:8006', 'user': 'root@pam', 'password': 'EUccs2!@#$'}\n",
    "]\n",
    "\n",
    "def format_uptime(seconds):\n",
    "    days = seconds // 86400\n",
    "    hours = (seconds % 86400) // 3600\n",
    "    return f\"{days}d {hours}h\"\n",
    "\n",
    "# âœ… tenant ê°’ì„ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜\n",
    "def get_tenant_from_host(host):\n",
    "    if 'eu-central-1' in host:\n",
    "        if 'prd' in host:\n",
    "            return 'FR2-PRD'\n",
    "        elif 'stg' in host:\n",
    "            return 'FR2-STG'\n",
    "        else:\n",
    "            return 'KR2-ADMIN'\n",
    "    elif 'eu-central-2' in host:\n",
    "        if 'prd' in host:\n",
    "            return 'FR7-PRD'\n",
    "        elif 'stg' in host:\n",
    "            return 'FR7-STG'\n",
    "        else:\n",
    "            return 'FR7-ADMIN'\n",
    "    else:\n",
    "        return 'UNKNOWN'\n",
    "\n",
    "current_date = datetime.now().strftime(\"%Y%m%d\")\n",
    "all_dfs = []\n",
    "\n",
    "for server in proxmox_servers:\n",
    "    proxmox = ProxmoxAPI(server['host'], user=server['user'], password=server['password'], verify_ssl=False)\n",
    "    tenant = get_tenant_from_host(server['host'])\n",
    "\n",
    "    cluster_resources = proxmox.cluster.resources.get(type='vm')\n",
    "    cluster_df = pd.DataFrame(cluster_resources)\n",
    "\n",
    "    vm_ip_list = []\n",
    "    for node in proxmox.nodes.get():\n",
    "        node_name = node['node']\n",
    "        vms = proxmox.nodes(node_name).qemu.get()\n",
    "\n",
    "        for vm in vms:\n",
    "            vmid = vm['vmid']\n",
    "            config = proxmox.nodes(node_name).qemu(vmid).config.get()\n",
    "            ipconfig = config.get('ipconfig0', None)\n",
    "\n",
    "            ip = None\n",
    "            if ipconfig:\n",
    "                match = re.search(r'ip=([\\d.]+)', ipconfig)\n",
    "                if match:\n",
    "                    ip = match.group(1)\n",
    "\n",
    "            vm_ip_list.append({\n",
    "                'vmid': int(vmid),\n",
    "                'cloud_init_ip': ip\n",
    "            })\n",
    "\n",
    "    ip_df = pd.DataFrame(vm_ip_list)\n",
    "    merged_df = pd.merge(cluster_df, ip_df, on='vmid', how='left')\n",
    "\n",
    "    merged_df['cpu'] = (merged_df['cpu'] * 100).round(2)\n",
    "    merged_df['mem'] = (merged_df['mem'] / (1024**3)).round(2)\n",
    "    merged_df['maxmem'] = (merged_df['maxmem'] / (1024**3)).round(2)\n",
    "    merged_df['maxdisk'] = (merged_df['maxdisk'] / (1024**3)).round(2)\n",
    "    merged_df['uptime'] = merged_df['uptime'].apply(format_uptime)\n",
    "\n",
    "    merged_df['tenant'] = tenant\n",
    "\n",
    "    final_df = merged_df[['tenant', 'vmid', 'name', 'node', 'status', 'cloud_init_ip', \n",
    "                          'cpu', 'maxcpu', 'mem', 'maxmem', 'disk', 'maxdisk', 'uptime']]\n",
    "    all_dfs.append(final_df)\n",
    "\n",
    "# âœ… ëª¨ë“  ì„œë²„ ë°ì´í„°ë¥¼ í•˜ë‚˜ë¡œ í•©ì¹¨\n",
    "combined_df = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "# âœ… Excelë¡œ ì €ì¥ (í•˜ë‚˜ì˜ ì‹œíŠ¸)\n",
    "excel_path = f\"C:\\\\Beomjun\\\\csv\\\\Proxmox\\\\proxmox_info_combined_{current_date}.xlsx\"\n",
    "combined_df.to_excel(excel_path, sheet_name=\"Proxmox_All\", index=False)\n",
    "\n",
    "print(f\"\\nâœ… All Proxmox data exported to: {excel_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726ffa52-7a3a-4130-87f5-84dae31d2f2f",
   "metadata": {},
   "source": [
    "## LB VIP ìˆ˜ëŸ‰ ë³€í™” ìˆ˜ì§‘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17057613-4235-4080-a4f4-657a1b83b114",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime, timedelta\n",
    "import urllib3\n",
    "import subprocess\n",
    "from openpyxl import Workbook\n",
    "\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "# .env ë¡œë“œ\n",
    "load_dotenv(dotenv_path=\"config/ctrix.env\")\n",
    "\n",
    "# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ\n",
    "# IP ë¦¬ìŠ¤íŠ¸ ë§Œë“¤ê¸°\n",
    "NS_IPS_FR2 = os.getenv(\"NS_IPS_FR2\", \"\").split(\",\")\n",
    "NS_IPS_FR7 = os.getenv(\"NS_IPS_FR7\", \"\").split(\",\")\n",
    "\n",
    "# ê°ê° ê³µë°± ì œê±°\n",
    "ip_list_fr2 = [ip.strip() for ip in NS_IPS_FR2 if ip.strip()]\n",
    "ip_list_fr7 = [ip.strip() for ip in NS_IPS_FR7 if ip.strip()]\n",
    "\n",
    "NITRO_USERNAME = os.getenv(\"NITRO_USERNAME\")\n",
    "NITRO_PASSWORD = os.getenv(\"NITRO_PASSWORD\")\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "VERIFY_SSL = False  # ìì²´ì„œëª… ì¸ì¦ì„œ ë¬´ì‹œ\n",
    "\n",
    "VPN_FR2_NAME = \"EU2-FR2\"\n",
    "VPN_FR7_NAME = \"EU2-FR7\"\n",
    "USERNAME = \"spark\"\n",
    "PASSWORD = \"tmvkzm1!\"\n",
    "\n",
    "# IPì™€ Tenant ë§¤í•‘ ë¡œë”©\n",
    "IP_TENANT_MAPPING = {}\n",
    "tenant_mapping_fr2 = os.getenv(\"TENANT_MAPPING_FR2\", \"\")\n",
    "tenant_mapping_fr7 = os.getenv(\"TENANT_MAPPING_FR7\", \"\")\n",
    "\n",
    "for item in tenant_mapping_fr2.split(\",\"):\n",
    "    if \":\" in item:\n",
    "        ip, tenant = item.split(\":\")\n",
    "        IP_TENANT_MAPPING[ip.strip()] = tenant.strip()\n",
    "\n",
    "for item in tenant_mapping_fr7.split(\",\"):\n",
    "    if \":\" in item:\n",
    "        ip, tenant = item.split(\":\")\n",
    "        IP_TENANT_MAPPING[ip.strip()] = tenant.strip()\n",
    "\n",
    "print(\"mapping info!\", IP_TENANT_MAPPING)\n",
    "\n",
    "# VPN ê´€ë ¨ í•¨ìˆ˜\n",
    "def is_vpn_connected(vpn_name):\n",
    "    result = subprocess.run(['rasdial'], capture_output=True, text=True)\n",
    "    return vpn_name.lower() in result.stdout.lower()\n",
    "\n",
    "def connect_vpn(vpn_name, username, password):\n",
    "    print(f\"[INFO] Connecting to VPN: {vpn_name}\")\n",
    "    subprocess.run(['rasdial', vpn_name, username, password])\n",
    "\n",
    "def disconnect_vpn(vpn_name):\n",
    "    print(f\"[INFO] Disconnecting VPN: {vpn_name}\")\n",
    "    subprocess.run(['rasdial', vpn_name, '/disconnect'])\n",
    "\n",
    "# Citrix API í•¨ìˆ˜\n",
    "def login(session, base_url):\n",
    "    url = f\"{base_url}/config/login\"\n",
    "    payload = {\"login\": {\"username\": NITRO_USERNAME, \"password\": NITRO_PASSWORD}}\n",
    "    response = session.post(url, json=payload, headers=HEADERS)\n",
    "    response.raise_for_status()\n",
    "\n",
    "def get_lb_vips(session, base_url):\n",
    "    url = f\"{base_url}/config/lbvserver\"\n",
    "    response = session.get(url, headers=HEADERS)\n",
    "    response.raise_for_status()\n",
    "    lb_list = response.json().get(\"lbvserver\", [])\n",
    "    return lb_list\n",
    "\n",
    "def logout(session, base_url):\n",
    "    url = f\"{base_url}/config/logout\"\n",
    "    payload = {\"logout\": {}}\n",
    "    session.post(url, json=payload, headers=HEADERS)\n",
    "\n",
    "# LB ìˆ˜ì§‘ í•¨ìˆ˜\n",
    "def collect_lb_info(region, vpn_name, ip_list):\n",
    "    if is_vpn_connected(vpn_name):\n",
    "        print(f\"[INFO] VPN {vpn_name} is already connected.\")\n",
    "    else:\n",
    "        print(f\"[INFO] VPN {vpn_name} not connected. Attempting connection...\")\n",
    "        connect_vpn(vpn_name, USERNAME, PASSWORD)\n",
    "\n",
    "    lb_data = []\n",
    "    for ip in ip_list:\n",
    "        tenant = IP_TENANT_MAPPING.get(ip, \"UNKNOWN\")\n",
    "        print(f\"[INFO] Collecting LB info from {tenant} ({ip})\")\n",
    "        base_url = f\"https://{ip}/nitro/v1\"\n",
    "        session = requests.Session()\n",
    "        session.verify = VERIFY_SSL\n",
    "\n",
    "        try:\n",
    "            login(session, base_url)\n",
    "            lb_list = get_lb_vips(session, base_url)\n",
    "\n",
    "            for lb in lb_list:\n",
    "                lb_name = lb.get('name')\n",
    "                lb_ip = lb.get('ipv46')\n",
    "                lb_port = lb.get('port')\n",
    "                service_type = lb.get('servicetype')\n",
    "                \n",
    "                if lb_ip == \"0.0.0.0\":\n",
    "                    continue\n",
    "                \n",
    "                lb_data.append([tenant, ip, lb_name, lb_ip, lb_port, service_type])\n",
    "\n",
    "        except requests.RequestException as e:\n",
    "            print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ ({ip}):\", e)\n",
    "\n",
    "        finally:\n",
    "            logout(session, base_url)\n",
    "\n",
    "    disconnect_vpn(vpn_name)\n",
    "    \n",
    "    return lb_data  # âœ… DataFrameì´ ì•„ë‹Œ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜\n",
    "\n",
    "\n",
    "def compare_yesterday():\n",
    "    # ë‚ ì§œ ì„¤ì •\n",
    "    current_date = datetime.now().strftime(\"%Y%m%d\")\n",
    "    yesterday_date = (datetime.now() - timedelta(days=1)).strftime(\"%Y%m%d\")\n",
    "    \n",
    "    print(\"today:\", current_date)\n",
    "    print(\"yesterday:\", yesterday_date)\n",
    "    \n",
    "    # ê²½ë¡œ ì„¤ì •\n",
    "    today_path = f\"C:\\\\Beomjun\\\\csv\\\\LB\\\\lb_info_{current_date}.ods\"\n",
    "    yesterday_path = f\"C:\\\\Beomjun\\\\csv\\\\LB\\\\lb_info_{yesterday_date}.ods\"\n",
    "    \n",
    "    # file_path=os.path.abspath(\"\")\n",
    "    # srcpath = findfile(f\"eu_adminrc_{yesterday_date}.csv.org\", file_path)\n",
    "    # dir, file = os.path.split(srcpath)\n",
    "    # shutil.copy2(srcpath, dir+f\"\\eu_adminrc_{yesterday_date}.csv\")\n",
    "        \n",
    "    # CSV ë¡œë“œ\n",
    "    df_today = pd.read_excel(today_path, engine='odf')\n",
    "    df_yesterday = pd.read_excel(yesterday_path, engine='odf')\n",
    "    \n",
    "    # ID ê¸°ì¤€ìœ¼ë¡œ ì°¨ì§‘í•© ì—°ì‚°\n",
    "    today_ids = set(df_today['LB_Name'])\n",
    "    yesterday_ids = set(df_yesterday['LB_Name'])\n",
    "    \n",
    "    # ì¶”ê°€ëœ VM: ì˜¤ëŠ˜ì—ëŠ” ìˆê³  ì–´ì œëŠ” ì—†ë˜ ê²ƒ\n",
    "    added_ids = today_ids - yesterday_ids\n",
    "    df_added = df_today[df_today['LB_Name'].isin(added_ids)]\n",
    "    \n",
    "    # ì‚­ì œëœ VM: ì–´ì œëŠ” ìˆì—ˆëŠ”ë° ì˜¤ëŠ˜ì€ ì—†ëŠ” ê²ƒ\n",
    "    deleted_ids = yesterday_ids - today_ids\n",
    "    df_deleted = df_yesterday[df_yesterday['LB_Name'].isin(deleted_ids)]\n",
    "    \n",
    "    # ê²°ê³¼ ì¶œë ¥\n",
    "    print(\"\\nâœ… ì˜¤ëŠ˜ ì¶”ê°€ëœ VM:\")\n",
    "    print(df_added)\n",
    "    \n",
    "    print(\"\\nâŒ ì˜¤ëŠ˜ ì‚­ì œëœ VM:\")\n",
    "    print(df_deleted)\n",
    "\n",
    "    return df_added, df_deleted\n",
    "\n",
    "\n",
    "def add_document(df_today, df_added, df_deleted):\n",
    "    document.add_heading('LB í˜„í™©', level=1) \n",
    "    total = len(df_today)\n",
    "    \n",
    "    document.add_paragraph(f'ì´ {total}ê±´', style='List Bullet')\n",
    "\n",
    "    # Pivoting\n",
    "    df = preprocess_df_LB(df_today)\n",
    "    # pivot, total = getPivotTable(df, month)\n",
    "    \n",
    "    # Chart - Pie ì°¨íŠ¸\n",
    "    region_pivot, _ = getPivotTable_new(df, 'Tenant')\n",
    "    # tenant_pivot, _ = getPivotTable_new(df, 'Tenant')\n",
    "    \n",
    "    source1 = region_pivot\n",
    "    # source2 = tenant_pivot\n",
    "    \n",
    "    print(source1)\n",
    "    # print(source2)\n",
    "    \n",
    "    # Chart\n",
    "    # if incompleted == 0:\n",
    "    chart1 = getPieChart_tenant(source1)\n",
    "    # chart2 = getPieChart_tenant(source2)\n",
    "    # else:\n",
    "    #     source = flatten_2d(data)\n",
    "    #     chart = getStackedHBarChart(source)    \n",
    "    \n",
    "    # source = pivot\n",
    "    # if incompleted == 0:\n",
    "    #     chart = getPieChart(source)\n",
    "    # else:\n",
    "    #     chart = getStackedHBarChart1(source)\n",
    "    chart1.save(f'./charts/LB_1.png')\n",
    "    # chart2.save(f'./charts/vm_2.png')\n",
    "\n",
    "    # p = document.add_paragraph('')\n",
    "    # run = p.add_run()\n",
    "    # run.add_break(WD_BREAK.LINE)\n",
    "    \n",
    "    table = document.add_table(rows=1, cols=1)\n",
    "    cell = table.rows[0].cells[0]\n",
    "    paragraph = cell.paragraphs[0]\n",
    "    paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER  # ìˆ˜í‰ ì¤‘ì•™ ì •ë ¬\n",
    "    run = paragraph.add_run(\"í…Œë„ŒíŠ¸ë³„\")\n",
    "    run.font.size = Pt(12)  # í°íŠ¸ í¬ê¸° ì¡°ì ˆ (ì„ íƒ)\n",
    "    run.bold = True  # êµµê²Œ (ì„ íƒ)\n",
    "    \n",
    "    # ì´ë¯¸ì§€ ì¶”ê°€ (ë³„ë„ ë¬¸ë‹¨ ìƒì„±í•˜ì—¬ ì•„ë˜ë¡œ ì •ë ¬ë˜ê²Œ)\n",
    "    paragraph_img = cell.add_paragraph()\n",
    "    paragraph_img.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "    run_img = paragraph_img.add_run()\n",
    "    run.add_picture(f'./charts/LB_1.png')\n",
    "    # run.add_picture(f'./charts/LB_1.png', width=Inches(3.3))\n",
    "    \n",
    "    # Document\n",
    "    document.add_paragraph(f'ì „ì¼ ëŒ€ë¹„ ì¶”ê°€ëœ LB({len(df_added)}ê±´)', style='List Bullet')\n",
    "    \n",
    "    if len(df_added) == 0:\n",
    "        pass\n",
    "    else:\n",
    "        addTable_LB(df_added)\n",
    "        \n",
    "    p = document.add_paragraph('')\n",
    "    run = p.add_run()\n",
    "    run.add_break(WD_BREAK.LINE)\n",
    "    \n",
    "    document.add_paragraph(f'ì „ì¼ ëŒ€ë¹„ ì‚­ì œëœ LB({len(df_deleted)}ê±´)', style='List Bullet')\n",
    "    # A-B (ì‚­ì œëœ ê±´)\n",
    "    # df_result_sub = pd.concat([df_premonth,df_curmonth,df_curmonth]).drop_duplicates(keep=False)\n",
    "    # print(df_result_sub)\n",
    "    \n",
    "    if len(df_deleted) == 0:\n",
    "        pass\n",
    "    else:\n",
    "        addTable_LB(df_deleted)\n",
    "\n",
    "    document.save(f'C:\\\\Beomjun\\\\csv\\\\total_report_{current_date}.docx')\n",
    "\n",
    "# ìµœì¢… ì‹¤í–‰\n",
    "if __name__ == \"__main__\":\n",
    "    current_date = datetime.now().strftime(\"%Y%m%d\")\n",
    "    ods_file = f\"C:\\\\Beomjun\\\\csv\\\\LB\\\\lb_info_{current_date}.ods\"\n",
    "\n",
    "    print(\"[INFO] Starting collection for FR2\")\n",
    "    fr2_data = collect_lb_info(\"FR2\", VPN_FR2_NAME, ip_list_fr2)\n",
    "\n",
    "    print(\"[INFO] Starting collection for FR7\")\n",
    "    fr7_data = collect_lb_info(\"FR7\", VPN_FR7_NAME, ip_list_fr7)\n",
    "\n",
    "    # âœ… ë°ì´í„° ë³‘í•©\n",
    "    combined_data = fr2_data + fr7_data\n",
    "    columns = [\"Tenant\", \"NS_IP\", \"LB_Name\", \"LB_VIP\", \"Port\", \"Service_Type\"]\n",
    "    df_combined = pd.DataFrame(combined_data, columns=columns)\n",
    "\n",
    "    # # âœ… ODS íŒŒì¼ ì €ì¥\n",
    "    with pd.ExcelWriter(ods_file, engine='odf') as writer:\n",
    "        df_combined.to_excel(writer, sheet_name=\"LB_Info\", index=False)\n",
    "\n",
    "    df_added, df_deleted = compare_yesterday()\n",
    "    add_document(df_combined, df_added, df_deleted)\n",
    "    \n",
    "    print(f\"\\nâœ… ODS íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {ods_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c21b780-0729-41e0-946e-3b0bd5c73a1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d49b2f6-65aa-492e-8634-6b717c3edff6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
